{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d6c521-bce1-4171-8ffd-32cfe4134637",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行设备: cuda\n",
      ">>> 正在加载资源...\n",
      "\n",
      "共发现 184 种分子筛骨架。\n",
      "开始每组 10 个进行批量绘制...\n",
      "\n",
      "[1/19] 处理骨架: ['ACO', 'AEI', 'AEL', 'AEN', 'AET', 'AFG', 'AFI', 'AFN', 'AFO', 'AFR']\n",
      "正在绘制 Group 1...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_1.png\n",
      "[2/19] 处理骨架: ['AFS', 'AFT', 'AFV', 'AFX', 'AFY', 'AHT', 'APC', 'APD', 'AST', 'ASV']\n",
      "正在绘制 Group 2...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_2.png\n",
      "[3/19] 处理骨架: ['ATN', 'ATO', 'ATS', 'ATT', 'AVE', 'AVL', 'AWO', 'AWW', 'BEC', 'BOF']\n",
      "正在绘制 Group 3...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_3.png\n",
      "[4/19] 处理骨架: ['BOG', 'BOZ', 'BPH', 'BSV', 'CDO', 'CFI', 'CGF', 'CGS', 'CHA', 'CON']\n",
      "正在绘制 Group 4...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_4.png\n",
      "[5/19] 处理骨架: ['CSV', 'CZP', 'DDR', 'DFO', 'DFT', 'DOH', 'EAB', 'EDI', 'EEI', 'EMT']\n",
      "正在绘制 Group 5...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_5.png\n",
      "[6/19] 处理骨架: ['EON', 'ERI', 'ESV', 'ETL', 'ETR', 'ETV', 'EUO', 'EWS', 'EZT', 'FAU']\n",
      "正在绘制 Group 6...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_6.png\n",
      "[7/19] 处理骨架: ['FER', 'GIS', 'GIU', 'GME', 'GON', 'IFO', 'IFR', 'IFW', 'IFY', 'IHW']\n",
      "正在绘制 Group 7...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_7.png\n",
      "[8/19] 处理骨架: ['IMF', 'IRN', 'IRR', 'ISV', 'ITE', 'ITG', 'ITH', 'ITR', 'ITT', 'ITW']\n",
      "正在绘制 Group 8...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_8.png\n",
      "[9/19] 处理骨架: ['IWR', 'IWS', 'IWW', 'JRY', 'JSR', 'JST', 'JSW', 'KFI', 'LAU', 'LEV']\n",
      "正在绘制 Group 9...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_9.png\n",
      "[10/19] 处理骨架: ['LIO', 'LOS', 'LTA', 'LTF', 'LTL', 'MAR', 'MAZ', 'MEI', 'MEL', 'MER']\n",
      "正在绘制 Group 10...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_10.png\n",
      "[11/19] 处理骨架: ['MFI', 'MFS', 'MOR', 'MOZ', 'MRT', 'MSE', 'MSO', 'MTF', 'MTN', 'MTT']\n",
      "正在绘制 Group 11...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_11.png\n",
      "[12/19] 处理骨架: ['MTW', 'MWW', 'NAT', 'NON', 'NPT', 'OBW', 'OFF', 'OKO', 'OSO', 'OWE']\n",
      "正在绘制 Group 12...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_12.png\n",
      "[13/19] 处理骨架: ['PHI', 'PON', 'POS', 'PUN', 'PWN', 'PWO', 'PWW', 'RHO', 'RRO', 'RTE']\n",
      "正在绘制 Group 13...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_13.png\n",
      "[14/19] 处理骨架: ['RTH', 'RUT', 'SAF', 'SAO', 'SAS', 'SAT', 'SAV', 'SBE', 'SBN', 'SBS']\n",
      "正在绘制 Group 14...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_14.png\n",
      "[15/19] 处理骨架: ['SBT', 'SEW', 'SFE', 'SFF', 'SFG', 'SFH', 'SFN', 'SFO', 'SFS', 'SFW']\n",
      "正在绘制 Group 15...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_15.png\n",
      "[16/19] 处理骨架: ['SGT', 'SIV', 'SOD', 'SOF', 'SOR', 'SOS', 'SOV', 'SSF', 'SSY', 'STF']\n",
      "正在绘制 Group 16...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_16.png\n",
      "[17/19] 处理骨架: ['STI', 'STO', 'STT', 'STW', 'SVV', 'SWY', 'SZR', 'TER', 'THO', 'TOL']\n",
      "正在绘制 Group 17...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_17.png\n",
      "[18/19] 处理骨架: ['TON', 'TSC', 'TUN', 'UEI', 'UFI', 'UOS', 'UOV', 'UOZ', 'USI', 'UTL']\n",
      "正在绘制 Group 18...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_18.png\n",
      "[19/19] 处理骨架: ['VET', 'VFI', 'VNI', 'ZON']\n",
      "正在绘制 Group 19...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\Batch_Analysis_Group_19.png\n",
      "\n",
      "========================================\n",
      "全部任务完成！所有图片已保存至: C:\\Users\\admin\\Energymodel\\2-9\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import cm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "\n",
    "class Config:\n",
    "    BASE_PATH = r\"./data\"\n",
    "    DATASET_PATH = os.path.join(BASE_PATH, \"Energy_data.xlsx\")\n",
    "    PROCESSED_CACHE_PATH = r\"./models/cached_graphs_box64_cleaned.pt\"\n",
    "    MODEL_PATH = r\"./models/zeolite_3d_gnn_enriched_cleaned.pth\"\n",
    "    SAVE_DIR = r\"./\"\n",
    "    \n",
    "    TARGET_COLS = [\n",
    "        'Binding Energy (kJ/mol Si)',\n",
    "        'Directivity Energy (kJ/mol Si)',\n",
    "        'Competition Energy (kJ/mol Si)',\n",
    "        'Binding Energy (kJ/mol OSDA)',\n",
    "        'Competition Energy (kJ/mol OSDA)'\n",
    "    ]\n",
    "    \n",
    "    ATOM_EMBEDDING_DIM = 64\n",
    "    HIDDEN_DIM = 128\n",
    "    EMB_DIM_DEGREE = 8\n",
    "    EMB_DIM_CHARGE = 8\n",
    "    EMB_DIM_HYB = 8\n",
    "    EMB_DIM_AROMATIC = 4\n",
    "    EMB_DIM_CHIRAL = 4\n",
    "    VOXEL_SIZE = 64\n",
    "    VOXEL_RES = 0.5\n",
    "    SIGMA = 0.5\n",
    "    MIN_SAMPLES_PER_TOPO = 0\n",
    "\n",
    "if not os.path.exists(Config.SAVE_DIR):\n",
    "    os.makedirs(Config.SAVE_DIR)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"运行设备: {device}\")\n",
    "\n",
    "\n",
    "def coords_to_voxel(coords, grid_size=32, res=0.5, sigma=0.5):\n",
    "    grid = np.zeros((grid_size, grid_size, grid_size), dtype=np.float32)\n",
    "    limit = (grid_size * res) / 2.0\n",
    "    mask = (coords[:, 0] > -limit) & (coords[:, 0] < limit) & \\\n",
    "           (coords[:, 1] > -limit) & (coords[:, 1] < limit) & \\\n",
    "           (coords[:, 2] > -limit) & (coords[:, 2] < limit)\n",
    "    valid_coords = coords[mask]\n",
    "    if len(valid_coords) == 0: return grid\n",
    "    indices = ((valid_coords + limit) / res).astype(int)\n",
    "    indices = np.clip(indices, 0, grid_size - 1)\n",
    "    for idx in indices:\n",
    "        x, y, z = idx\n",
    "        x_min, x_max = max(0, x-1), min(grid_size, x+2)\n",
    "        y_min, y_max = max(0, y-1), min(grid_size, y+2)\n",
    "        z_min, z_max = max(0, z-1), min(grid_size, z+2)\n",
    "        grid[x_min:x_max, y_min:y_max, z_min:z_max] += 1.0\n",
    "    return np.clip(grid, 0, 1.0)\n",
    "\n",
    "def get_rotation_matrix_z(angle_deg):\n",
    "    rad = np.radians(angle_deg)\n",
    "    cos_a, sin_a = np.cos(rad), np.sin(rad)\n",
    "    return np.array([[cos_a, -sin_a, 0], [sin_a, cos_a, 0], [0, 0, 1]])\n",
    "\n",
    "class Voxel3DCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(2, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(16)\n",
    "        self.pool1 = nn.MaxPool3d(2)\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(32)\n",
    "        self.pool2 = nn.MaxPool3d(2)\n",
    "        self.conv3 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm3d(64)\n",
    "        self.pool3 = nn.MaxPool3d(2)\n",
    "        self.fc = nn.Linear(64 * 8 * 8 * 8, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return x\n",
    "\n",
    "class DualBranchGNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb_atom = nn.Embedding(120, Config.ATOM_EMBEDDING_DIM)\n",
    "        self.emb_degree = nn.Embedding(12, Config.EMB_DIM_DEGREE)\n",
    "        self.emb_charge = nn.Embedding(15, Config.EMB_DIM_CHARGE)\n",
    "        self.emb_hyb = nn.Embedding(8, Config.EMB_DIM_HYB)\n",
    "        self.emb_aromatic = nn.Embedding(2, Config.EMB_DIM_AROMATIC)\n",
    "        self.emb_chiral = nn.Embedding(4, Config.EMB_DIM_CHIRAL)\n",
    "        \n",
    "        total_emb_dim = (Config.ATOM_EMBEDDING_DIM + Config.EMB_DIM_DEGREE + \n",
    "                         Config.EMB_DIM_CHARGE + Config.EMB_DIM_HYB + \n",
    "                         Config.EMB_DIM_AROMATIC + Config.EMB_DIM_CHIRAL)\n",
    "        \n",
    "        self.mol_conv1 = GCNConv(total_emb_dim + 1, Config.HIDDEN_DIM)\n",
    "        self.mol_conv2 = GCNConv(Config.HIDDEN_DIM, Config.HIDDEN_DIM)\n",
    "        self.zeo_conv1 = GCNConv(total_emb_dim, Config.HIDDEN_DIM)\n",
    "        self.zeo_conv2 = GCNConv(Config.HIDDEN_DIM, Config.HIDDEN_DIM)\n",
    "        self.voxel_cnn = Voxel3DCNN()\n",
    "        self.global_encoder = nn.Sequential(\n",
    "            nn.Linear(17, 64), nn.ReLU(),\n",
    "            nn.Linear(64, Config.HIDDEN_DIM), nn.BatchNorm1d(Config.HIDDEN_DIM), nn.ReLU()\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(Config.HIDDEN_DIM * 4, 512), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256), nn.ReLU(),\n",
    "            nn.Linear(256, len(Config.TARGET_COLS))\n",
    "        )\n",
    "\n",
    "    def _embed_features(self, x_idx):\n",
    "        return torch.cat([\n",
    "            self.emb_atom(x_idx[:, 0]), self.emb_degree(x_idx[:, 1]),\n",
    "            self.emb_charge(x_idx[:, 2]), self.emb_hyb(x_idx[:, 3]),\n",
    "            self.emb_aromatic(x_idx[:, 4]), self.emb_chiral(x_idx[:, 5])\n",
    "        ], dim=1)\n",
    "\n",
    "    def forward(self, mol_batch, zeo_batch, voxel_batch):\n",
    "        x_m_emb = self._embed_features(mol_batch.x)\n",
    "        x_m_in = torch.cat([x_m_emb, mol_batch.x_charge], dim=1)\n",
    "        x_m_out = F.relu(self.mol_conv2(F.relu(self.mol_conv1(x_m_in, mol_batch.edge_index, edge_weight=mol_batch.edge_weight)), mol_batch.edge_index, edge_weight=mol_batch.edge_weight))\n",
    "        feat_m = global_mean_pool(x_m_out, mol_batch.batch)\n",
    "        \n",
    "        x_z_emb = self._embed_features(zeo_batch.x)\n",
    "        x_z_out = F.relu(self.zeo_conv2(F.relu(self.zeo_conv1(x_z_emb, zeo_batch.edge_index)), zeo_batch.edge_index))\n",
    "        feat_z = global_mean_pool(x_z_out, zeo_batch.batch)\n",
    "        \n",
    "        feat_v = self.voxel_cnn(voxel_batch)\n",
    "        global_attr = mol_batch.global_attr.squeeze(1) if mol_batch.global_attr.dim() == 3 else mol_batch.global_attr\n",
    "        feat_global = self.global_encoder(global_attr)\n",
    "        \n",
    "        return self.head(torch.cat([feat_m, feat_z, feat_global, feat_v], dim=1))\n",
    "\n",
    "\n",
    "def load_resources():\n",
    "    print(\"Loading\")\n",
    "    model = DualBranchGNN().to(device)\n",
    "    model.load_state_dict(torch.load(Config.MODEL_WEIGHT_PATH, map_location=device, weights_only=False))\n",
    "    model.eval()\n",
    "    \n",
    "    cache_data = torch.load(Config.PROCESSED_CACHE_PATH, weights_only=False)\n",
    "    df = pd.read_excel(Config.DATASET_PATH, engine='openpyxl')\n",
    "    \n",
    "    valid_topos = df['Topology Code'].value_counts()[df['Topology Code'].value_counts() >= Config.MIN_SAMPLES_PER_TOPO].index\n",
    "    df_filtered = df[df['Topology Code'].isin(valid_topos)].reset_index(drop=True)\n",
    "    \n",
    "    train_idx, _ = train_test_split(list(range(len(df_filtered))), train_size=0.8, random_state=42)\n",
    "    \n",
    "    train_targets = []\n",
    "    mol_cache, zeo_cache = cache_data['mol_cache'], cache_data['zeo_cache']\n",
    "    for idx in train_idx:\n",
    "        row = df_filtered.iloc[idx]\n",
    "        if row['CID'] in mol_cache and row['Topology Code'] in zeo_cache:\n",
    "            targets = row[Config.TARGET_COLS].values.astype(float)\n",
    "            if not np.isnan(targets).any(): train_targets.append(targets)\n",
    "            \n",
    "    target_scaler = StandardScaler()\n",
    "    target_scaler.fit(np.array(train_targets))\n",
    "    props_scaler = StandardScaler()\n",
    "    all_props = [mol_cache[cid].global_attr.numpy().flatten() for cid in mol_cache]\n",
    "    props_scaler.fit(np.array(all_props))\n",
    "    \n",
    "    return model, cache_data, df_filtered, target_scaler, props_scaler\n",
    "\n",
    "def get_most_unstable_molecule(df, topo_code):\n",
    "    subset = df[df['Topology Code'] == topo_code]\n",
    "    if len(subset) == 0: return None\n",
    "    target_col = Config.TARGET_COLS[0]\n",
    "    most_unstable_row = subset.loc[subset[target_col].idxmax()]\n",
    "    return most_unstable_row['CID'], most_unstable_row[target_col]\n",
    "\n",
    "\n",
    "def compute_rotation_profile(model, cid, topo, cache_data, t_scaler, p_scaler):\n",
    "    mol_raw = cache_data['mol_cache'].get(cid)\n",
    "    zeo_raw = cache_data['zeo_cache'].get(topo)\n",
    "    if not mol_raw or not zeo_raw: return None, None\n",
    "\n",
    "    angles = np.arange(0, 360, 10)\n",
    "    preds_list = []\n",
    "    \n",
    "    if hasattr(mol_raw, 'pos_variants'): mol_base = mol_raw.pos_variants[0].numpy()\n",
    "    else: mol_base = mol_raw.pos.numpy()\n",
    "    mol_base = mol_base - np.mean(mol_base, axis=0)\n",
    "    \n",
    "    zeo_coords = zeo_raw.pos_super.numpy() if hasattr(zeo_raw, 'pos_super') else zeo_raw.pos.numpy()\n",
    "    grid_zeo = coords_to_voxel(zeo_coords, Config.VOXEL_SIZE, Config.VOXEL_RES, Config.SIGMA)\n",
    "    \n",
    "    props_norm = p_scaler.transform(mol_raw.global_attr.numpy())\n",
    "    global_attr = torch.tensor(props_norm, dtype=torch.float).to(device)\n",
    "    \n",
    "    batch_size_rot = 12\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(angles), batch_size_rot):\n",
    "            ang_batch = angles[i:i+batch_size_rot]\n",
    "            mol_list, voxel_list = [], []\n",
    "            for ang in ang_batch:\n",
    "                rot_mat = get_rotation_matrix_z(ang)\n",
    "                mol_rot = np.dot(mol_base, rot_mat)\n",
    "                grid_mol = coords_to_voxel(mol_rot, Config.VOXEL_SIZE, Config.VOXEL_RES, Config.SIGMA)\n",
    "                voxel_list.append(torch.tensor(np.stack([grid_mol, grid_zeo], axis=0), dtype=torch.float))\n",
    "                m = mol_raw.clone()\n",
    "                m.pos = torch.tensor(mol_rot, dtype=torch.float)\n",
    "                m.global_attr = global_attr\n",
    "                if hasattr(m, 'pos_variants'): del m.pos_variants\n",
    "                mol_list.append(m)\n",
    "            \n",
    "            mol_batch_gpu = Batch.from_data_list(mol_list).to(device)\n",
    "            voxel_gpu = torch.stack(voxel_list).to(device)\n",
    "            zeo_list_expanded = [zeo_raw.clone() for _ in range(len(mol_list))]\n",
    "            zeo_batch_gpu = Batch.from_data_list(zeo_list_expanded).to(device)\n",
    "            \n",
    "            pred = model(mol_batch_gpu, zeo_batch_gpu, voxel_gpu)\n",
    "            preds_list.append(pred.cpu().numpy())\n",
    "\n",
    "    preds_all = np.vstack(preds_list)\n",
    "    preds_real = t_scaler.inverse_transform(preds_all)\n",
    "    return angles, preds_real[:, 0]\n",
    "\n",
    "\n",
    "def plot_topo_batch(topo_group, group_id, df, model, cache_data, t_scaler, p_scaler):\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "    plt.rcParams['font.sans-serif'] = ['Arial', 'Helvetica', 'DejaVu Sans']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(24, 16), subplot_kw=dict(polar=True))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    try: magma = matplotlib.colormaps['magma']\n",
    "    except: magma = plt.get_cmap('magma')\n",
    "\n",
    "    new_colors = magma(np.linspace(0.3, 1.0, 256))\n",
    "    new_cmap = mcolors.LinearSegmentedColormap.from_list(\"trunc_magma\", new_colors)\n",
    "    color = new_cmap(0.6)\n",
    "    \n",
    "    print(f\"Group {group_id}...\")\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        if i >= len(topo_group):\n",
    "            ax.set_visible(False)\n",
    "            continue\n",
    "            \n",
    "        topo = topo_group[i]\n",
    "        \n",
    "        cid, worst_energy = get_most_unstable_molecule(df, topo)\n",
    "        if cid is None:\n",
    "            ax.set_visible(False)\n",
    "            continue\n",
    "            \n",
    "        angles, energies = compute_rotation_profile(model, cid, topo, cache_data, t_scaler, p_scaler)\n",
    "        if energies is None:\n",
    "            ax.set_visible(False)\n",
    "            continue\n",
    "        \n",
    "        values = np.abs(energies)\n",
    "        theta = np.deg2rad(angles)\n",
    "        theta = np.concatenate((theta, [theta[0]]))\n",
    "        values = np.concatenate((values, [values[0]]))\n",
    "        \n",
    "        ax.plot(theta, values, color=color, linewidth=4)\n",
    "        ax.fill(theta, values, color=color, alpha=0.5)\n",
    "        \n",
    "        max_val = np.max(values)\n",
    "        ax.set_ylim(0, max_val * 1.25)\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.grid(True, linestyle='--', alpha=0.3)\n",
    "        \n",
    "        ax.set_title(f\"{topo}\", weight='bold', size=48, pad=20)\n",
    "        \n",
    "        mean_e = np.mean(energies)\n",
    "        std_e = np.std(energies)\n",
    "        cv = (std_e / abs(mean_e)) * 100 if mean_e != 0 else 0\n",
    "        \n",
    "        ax.text(0.5, -0.15, f\"{mean_e:.2f}\", transform=ax.transAxes, \n",
    "                ha='center', va='center', fontsize=40, weight='bold', color='black')\n",
    "        \n",
    "        ax.text(0.5, -0.45, f\"{cv:.2f}%\", transform=ax.transAxes, \n",
    "                ha='center', va='center', fontsize=40, weight='bold', color='darkred')\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            ax.text(-0.25, -0.15, \"Mean:\", transform=ax.transAxes, \n",
    "                    ha='right', va='center', fontsize=40, weight='bold', color='gray')\n",
    "            ax.text(-0.25, -0.45, \"CV:\", transform=ax.transAxes, \n",
    "                    ha='right', va='center', fontsize=40, weight='bold', color='gray')\n",
    "\n",
    "    plt.subplots_adjust(top=0.88, bottom=0.15, hspace=0.35, wspace=0.3)\n",
    "    \n",
    "    save_path = os.path.join(Config.SAVE_DIR, f\"Batch_Analysis_Group_{group_id}.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"saved: {save_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, cache_data, df, t_scaler, p_scaler = load_resources()\n",
    "    \n",
    "    available_topos = list(cache_data['zeo_cache'].keys())\n",
    "    available_topos.sort()\n",
    "    \n",
    "    print(f\"\\ndiscoveries {len(available_topos)} Molecular sieve skeleton.\")\n",
    "    print(\"Begin batch plotting in groups of 10....\\n\")\n",
    "    \n",
    "    batch_size = 10\n",
    "    total_groups = math.ceil(len(available_topos) / batch_size)\n",
    "    \n",
    "    for i in range(total_groups):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, len(available_topos))\n",
    "        group_topos = available_topos[start_idx:end_idx]\n",
    "        \n",
    "        print(f\"[{i+1}/{total_groups}] Handling Skeleton: {group_topos}\")\n",
    "        plot_topo_batch(group_topos, i+1, df, model, cache_data, t_scaler, p_scaler)\n",
    "\n",
    "    print(f\"chart saved: {Config.SAVE_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (zeolite_3d)",
   "language": "python",
   "name": "zeolite_3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
