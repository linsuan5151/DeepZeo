{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c4ebf7-72d8-4b21-9607-6e14d3c35388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行设备: cuda\n",
      ">>> 正在加载资源...\n",
      "检测到共 184 个分子筛骨架，开始计算所有 CV 值以生成色谱...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "预计算: 100%|████████████████████████████████████████████████████████████████████████| 184/184 [00:37<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Range: 0.0000% - 9.2970%\n",
      "开始绘图...\n",
      "  --> 保存成功: C:\\Users\\admin\\Energymodel\\2-9\\All_Topologies_Row30.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patheffects as pe  \n",
    "from matplotlib import cm\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class Config:\n",
    "    BASE_PATH = r\"./data\"\n",
    "    DATASET_PATH = os.path.join(BASE_PATH, \"Energy_data.xlsx.xlsx\"))\n",
    "    PROCESSED_CACHE_PATH = r\"./models/cached_graphs_box64_cleaned.pt\"\n",
    "    MODEL_PATH = r\"./models/zeolite_3d_gnn_enriched_cleaned.pth\"\n",
    "    SAVE_DIR = r\"./\"\n",
    "    \n",
    "    TARGET_COLS = [\n",
    "        'Binding Energy (kJ/mol Si)',\n",
    "        'Directivity Energy (kJ/mol Si)',\n",
    "        'Competition Energy (kJ/mol Si)',\n",
    "        'Binding Energy (kJ/mol OSDA)',\n",
    "        'Competition Energy (kJ/mol OSDA)'\n",
    "    ]\n",
    "    \n",
    "    ATOM_EMBEDDING_DIM = 64\n",
    "    HIDDEN_DIM = 128\n",
    "    EMB_DIM_DEGREE = 8\n",
    "    EMB_DIM_CHARGE = 8\n",
    "    EMB_DIM_HYB = 8\n",
    "    EMB_DIM_AROMATIC = 4\n",
    "    EMB_DIM_CHIRAL = 4\n",
    "    VOXEL_SIZE = 64\n",
    "    VOXEL_RES = 0.5\n",
    "    SIGMA = 0.5\n",
    "    MIN_SAMPLES_PER_TOPO = 0\n",
    "\n",
    "if not os.path.exists(Config.SAVE_DIR):\n",
    "    os.makedirs(Config.SAVE_DIR)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"运行设备: {device}\")\n",
    "\n",
    "# =========================================\n",
    "# 1. 基础工具函数\n",
    "# =========================================\n",
    "def coords_to_voxel(coords, grid_size=32, res=0.5, sigma=0.5):\n",
    "    grid = np.zeros((grid_size, grid_size, grid_size), dtype=np.float32)\n",
    "    limit = (grid_size * res) / 2.0\n",
    "    mask = (coords[:, 0] > -limit) & (coords[:, 0] < limit) & \\\n",
    "           (coords[:, 1] > -limit) & (coords[:, 1] < limit) & \\\n",
    "           (coords[:, 2] > -limit) & (coords[:, 2] < limit)\n",
    "    valid_coords = coords[mask]\n",
    "    if len(valid_coords) == 0: return grid\n",
    "    indices = ((valid_coords + limit) / res).astype(int)\n",
    "    indices = np.clip(indices, 0, grid_size - 1)\n",
    "    for idx in indices:\n",
    "        x, y, z = idx\n",
    "        x_min, x_max = max(0, x-1), min(grid_size, x+2)\n",
    "        y_min, y_max = max(0, y-1), min(grid_size, y+2)\n",
    "        z_min, z_max = max(0, z-1), min(grid_size, z+2)\n",
    "        grid[x_min:x_max, y_min:y_max, z_min:z_max] += 1.0\n",
    "    return np.clip(grid, 0, 1.0)\n",
    "\n",
    "def get_rotation_matrix_z(angle_deg):\n",
    "    rad = np.radians(angle_deg)\n",
    "    cos_a, sin_a = np.cos(rad), np.sin(rad)\n",
    "    return np.array([[cos_a, -sin_a, 0], [sin_a, cos_a, 0], [0, 0, 1]])\n",
    "\n",
    "# =========================================\n",
    "# 2. 模型定义\n",
    "# =========================================\n",
    "class Voxel3DCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(2, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(16)\n",
    "        self.pool1 = nn.MaxPool3d(2)\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(32)\n",
    "        self.pool2 = nn.MaxPool3d(2)\n",
    "        self.conv3 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm3d(64)\n",
    "        self.pool3 = nn.MaxPool3d(2)\n",
    "        self.fc = nn.Linear(64 * 8 * 8 * 8, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return x\n",
    "\n",
    "class DualBranchGNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb_atom = nn.Embedding(120, Config.ATOM_EMBEDDING_DIM)\n",
    "        self.emb_degree = nn.Embedding(12, Config.EMB_DIM_DEGREE)\n",
    "        self.emb_charge = nn.Embedding(15, Config.EMB_DIM_CHARGE)\n",
    "        self.emb_hyb = nn.Embedding(8, Config.EMB_DIM_HYB)\n",
    "        self.emb_aromatic = nn.Embedding(2, Config.EMB_DIM_AROMATIC)\n",
    "        self.emb_chiral = nn.Embedding(4, Config.EMB_DIM_CHIRAL)\n",
    "        \n",
    "        total_emb_dim = (Config.ATOM_EMBEDDING_DIM + Config.EMB_DIM_DEGREE + \n",
    "                         Config.EMB_DIM_CHARGE + Config.EMB_DIM_HYB + \n",
    "                         Config.EMB_DIM_AROMATIC + Config.EMB_DIM_CHIRAL)\n",
    "        \n",
    "        self.mol_conv1 = GCNConv(total_emb_dim + 1, Config.HIDDEN_DIM)\n",
    "        self.mol_conv2 = GCNConv(Config.HIDDEN_DIM, Config.HIDDEN_DIM)\n",
    "        self.zeo_conv1 = GCNConv(total_emb_dim, Config.HIDDEN_DIM)\n",
    "        self.zeo_conv2 = GCNConv(Config.HIDDEN_DIM, Config.HIDDEN_DIM)\n",
    "        self.voxel_cnn = Voxel3DCNN()\n",
    "        self.global_encoder = nn.Sequential(\n",
    "            nn.Linear(17, 64), nn.ReLU(),\n",
    "            nn.Linear(64, Config.HIDDEN_DIM), nn.BatchNorm1d(Config.HIDDEN_DIM), nn.ReLU()\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(Config.HIDDEN_DIM * 4, 512), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256), nn.ReLU(),\n",
    "            nn.Linear(256, len(Config.TARGET_COLS))\n",
    "        )\n",
    "\n",
    "    def _embed_features(self, x_idx):\n",
    "        return torch.cat([\n",
    "            self.emb_atom(x_idx[:, 0]), self.emb_degree(x_idx[:, 1]),\n",
    "            self.emb_charge(x_idx[:, 2]), self.emb_hyb(x_idx[:, 3]),\n",
    "            self.emb_aromatic(x_idx[:, 4]), self.emb_chiral(x_idx[:, 5])\n",
    "        ], dim=1)\n",
    "\n",
    "    def forward(self, mol_batch, zeo_batch, voxel_batch):\n",
    "        x_m_emb = self._embed_features(mol_batch.x)\n",
    "        x_m_in = torch.cat([x_m_emb, mol_batch.x_charge], dim=1)\n",
    "        x_m_out = F.relu(self.mol_conv2(F.relu(self.mol_conv1(x_m_in, mol_batch.edge_index, edge_weight=mol_batch.edge_weight)), mol_batch.edge_index, edge_weight=mol_batch.edge_weight))\n",
    "        feat_m = global_mean_pool(x_m_out, mol_batch.batch)\n",
    "        \n",
    "        x_z_emb = self._embed_features(zeo_batch.x)\n",
    "        x_z_out = F.relu(self.zeo_conv2(F.relu(self.zeo_conv1(x_z_emb, zeo_batch.edge_index)), zeo_batch.edge_index))\n",
    "        feat_z = global_mean_pool(x_z_out, zeo_batch.batch)\n",
    "        \n",
    "        feat_v = self.voxel_cnn(voxel_batch)\n",
    "        global_attr = mol_batch.global_attr.squeeze(1) if mol_batch.global_attr.dim() == 3 else mol_batch.global_attr\n",
    "        feat_global = self.global_encoder(global_attr)\n",
    "        \n",
    "        return self.head(torch.cat([feat_m, feat_z, feat_global, feat_v], dim=1))\n",
    "\n",
    "# =========================================\n",
    "# 3. 资源加载\n",
    "# =========================================\n",
    "def load_resources():\n",
    "    print(\">>> 正在加载资源...\")\n",
    "    model = DualBranchGNN().to(device)\n",
    "    model.load_state_dict(torch.load(Config.MODEL_WEIGHT_PATH, map_location=device, weights_only=False))\n",
    "    model.eval()\n",
    "    \n",
    "    cache_data = torch.load(Config.PROCESSED_CACHE_PATH, weights_only=False)\n",
    "    df = pd.read_excel(Config.DATASET_PATH, engine='openpyxl')\n",
    "    \n",
    "    valid_topos = df['Topology Code'].value_counts()[df['Topology Code'].value_counts() >= Config.MIN_SAMPLES_PER_TOPO].index\n",
    "    df_filtered = df[df['Topology Code'].isin(valid_topos)].reset_index(drop=True)\n",
    "    \n",
    "    train_idx, _ = train_test_split(list(range(len(df_filtered))), train_size=0.8, random_state=42)\n",
    "    \n",
    "    train_targets = []\n",
    "    mol_cache, zeo_cache = cache_data['mol_cache'], cache_data['zeo_cache']\n",
    "    for idx in train_idx:\n",
    "        row = df_filtered.iloc[idx]\n",
    "        if row['CID'] in mol_cache and row['Topology Code'] in zeo_cache:\n",
    "            targets = row[Config.TARGET_COLS].values.astype(float)\n",
    "            if not np.isnan(targets).any(): train_targets.append(targets)\n",
    "            \n",
    "    target_scaler = StandardScaler()\n",
    "    target_scaler.fit(np.array(train_targets))\n",
    "    props_scaler = StandardScaler()\n",
    "    all_props = [mol_cache[cid].global_attr.numpy().flatten() for cid in mol_cache]\n",
    "    props_scaler.fit(np.array(all_props))\n",
    "    \n",
    "    return model, cache_data, df_filtered, target_scaler, props_scaler\n",
    "\n",
    "def get_most_unstable_molecule(df, topo_code):\n",
    "    subset = df[df['Topology Code'] == topo_code]\n",
    "    if len(subset) == 0: return None\n",
    "    target_col = Config.TARGET_COLS[0]\n",
    "    most_unstable_row = subset.loc[subset[target_col].idxmax()]\n",
    "    return most_unstable_row['CID'], most_unstable_row[target_col]\n",
    "\n",
    "# =========================================\n",
    "# 4. 旋转计算\n",
    "# =========================================\n",
    "def compute_rotation_profile(model, cid, topo, cache_data, t_scaler, p_scaler):\n",
    "    mol_raw = cache_data['mol_cache'].get(cid)\n",
    "    zeo_raw = cache_data['zeo_cache'].get(topo)\n",
    "    if not mol_raw or not zeo_raw: return None, None\n",
    "\n",
    "    angles = np.arange(0, 360, 10)\n",
    "    preds_list = []\n",
    "    \n",
    "    if hasattr(mol_raw, 'pos_variants'): mol_base = mol_raw.pos_variants[0].numpy()\n",
    "    else: mol_base = mol_raw.pos.numpy()\n",
    "    mol_base = mol_base - np.mean(mol_base, axis=0)\n",
    "    \n",
    "    zeo_coords = zeo_raw.pos_super.numpy() if hasattr(zeo_raw, 'pos_super') else zeo_raw.pos.numpy()\n",
    "    grid_zeo = coords_to_voxel(zeo_coords, Config.VOXEL_SIZE, Config.VOXEL_RES, Config.SIGMA)\n",
    "    \n",
    "    props_norm = p_scaler.transform(mol_raw.global_attr.numpy())\n",
    "    global_attr = torch.tensor(props_norm, dtype=torch.float).to(device)\n",
    "    \n",
    "    batch_size_rot = 12\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(angles), batch_size_rot):\n",
    "            ang_batch = angles[i:i+batch_size_rot]\n",
    "            mol_list, voxel_list = [], []\n",
    "            for ang in ang_batch:\n",
    "                rot_mat = get_rotation_matrix_z(ang)\n",
    "                mol_rot = np.dot(mol_base, rot_mat)\n",
    "                grid_mol = coords_to_voxel(mol_rot, Config.VOXEL_SIZE, Config.VOXEL_RES, Config.SIGMA)\n",
    "                voxel_list.append(torch.tensor(np.stack([grid_mol, grid_zeo], axis=0), dtype=torch.float))\n",
    "                m = mol_raw.clone()\n",
    "                m.pos = torch.tensor(mol_rot, dtype=torch.float)\n",
    "                m.global_attr = global_attr\n",
    "                if hasattr(m, 'pos_variants'): del m.pos_variants\n",
    "                mol_list.append(m)\n",
    "            \n",
    "            mol_batch_gpu = Batch.from_data_list(mol_list).to(device)\n",
    "            voxel_gpu = torch.stack(voxel_list).to(device)\n",
    "            zeo_list_expanded = [zeo_raw.clone() for _ in range(len(mol_list))]\n",
    "            zeo_batch_gpu = Batch.from_data_list(zeo_list_expanded).to(device)\n",
    "            \n",
    "            pred = model(mol_batch_gpu, zeo_batch_gpu, voxel_gpu)\n",
    "            preds_list.append(pred.cpu().numpy())\n",
    "\n",
    "    preds_all = np.vstack(preds_list)\n",
    "    preds_real = t_scaler.inverse_transform(preds_all)\n",
    "    return angles, preds_real[:, 0]\n",
    "\n",
    "# =========================================\n",
    "# 5. 绘图核心 (30个一排)\n",
    "# =========================================\n",
    "def plot_all_topologies_in_one(df, model, cache_data, t_scaler, p_scaler):\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "    plt.rcParams['font.sans-serif'] = ['Arial', 'Helvetica', 'DejaVu Sans']\n",
    "    \n",
    "    # 1. 获取所有可用的拓扑结构\n",
    "    available_topos = list(cache_data['zeo_cache'].keys())\n",
    "    available_topos.sort()\n",
    "    \n",
    "    print(f\"检测到共 {len(available_topos)} 个分子筛骨架，开始计算所有 CV 值以生成色谱...\")\n",
    "    \n",
    "    # 2. 预计算步骤\n",
    "    plot_data = []\n",
    "    all_cvs = []\n",
    "    \n",
    "    for topo in tqdm(available_topos, desc=\"预计算\"):\n",
    "        cid, worst_energy = get_most_unstable_molecule(df, topo)\n",
    "        if cid is None: continue\n",
    "        \n",
    "        angles, energies = compute_rotation_profile(model, cid, topo, cache_data, t_scaler, p_scaler)\n",
    "        if energies is None: continue\n",
    "        \n",
    "        mean_e = np.mean(energies)\n",
    "        std_e = np.std(energies)\n",
    "        cv = (std_e / abs(mean_e)) * 100 if mean_e != 0 else 0\n",
    "        \n",
    "        plot_data.append({\n",
    "            'topo': topo,\n",
    "            'mean': mean_e,\n",
    "            'cv': cv,\n",
    "            'angles': angles,\n",
    "            'energies': np.abs(energies)\n",
    "        })\n",
    "        all_cvs.append(cv)\n",
    "        \n",
    "    if not plot_data:\n",
    "        print(\"未找到有效数据。\")\n",
    "        return\n",
    "\n",
    "    # 3. 颜色映射配置 (Magma 30%-100%)\n",
    "    min_cv, max_cv = min(all_cvs), max(all_cvs)\n",
    "    print(f\"CV Range: {min_cv:.4f}% - {max_cv:.4f}%\")\n",
    "    \n",
    "    try: magma = matplotlib.colormaps['magma']\n",
    "    except: magma = plt.get_cmap('magma')\n",
    "    \n",
    "    new_colors = magma(np.linspace(0.3, 1.0, 256))\n",
    "    new_cmap = mcolors.LinearSegmentedColormap.from_list(\"trunc_magma\", new_colors)\n",
    "    norm = mcolors.Normalize(vmin=min_cv, vmax=max_cv)\n",
    "    \n",
    "    # 4. 布局计算 (强制 30 列)\n",
    "    N = len(plot_data)\n",
    "    cols = 27  # 核心修改：一排30个\n",
    "    rows = int(math.ceil(N / cols))\n",
    "    \n",
    "    # 画布尺寸\n",
    "    # 30列 * 3英寸 = 90英寸宽，这能保证在高清保存时不超限且文字清晰\n",
    "    fig_w, fig_h = cols * 3, rows * 3\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(fig_w, fig_h), subplot_kw=dict(polar=True))\n",
    "    \n",
    "    # 如果只有1行，axes 是一维数组，需要处理\n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    print(\"开始绘图...\")\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i >= N:\n",
    "            ax.set_visible(False)\n",
    "            continue\n",
    "            \n",
    "        data = plot_data[i]\n",
    "        \n",
    "        # 颜色\n",
    "        color = new_cmap(norm(data['cv']))\n",
    "        \n",
    "        theta = np.deg2rad(data['angles'])\n",
    "        values = data['energies']\n",
    "        theta = np.concatenate((theta, [theta[0]]))\n",
    "        values = np.concatenate((values, [values[0]]))\n",
    "        \n",
    "        # 绘图\n",
    "        ax.plot(theta, values, color=color, linewidth=3)\n",
    "        ax.fill(theta, values, color=color, alpha=0.8)\n",
    "        \n",
    "        max_val = np.max(values)\n",
    "        ax.set_ylim(0, max_val * 1.25)\n",
    "        \n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.grid(True, linestyle='--', alpha=0.3)\n",
    "        ax.spines['polar'].set_visible(False)\n",
    "        \n",
    "        # === 中心文字 ===\n",
    "        center_text = f\"{data['topo']}\\n{data['mean']:.1f}\"\n",
    "        \n",
    "        # 字体调整为 28，配合加粗描边，在3x3的格子中会非常显眼\n",
    "        txt = ax.text(0, 0, center_text, \n",
    "                      ha='center', va='center', \n",
    "                      fontsize=51, weight='bold', color='white', zorder=10)\n",
    "        \n",
    "        txt.set_path_effects([pe.withStroke(linewidth=3.5, foreground='black')])\n",
    "\n",
    "    # Colorbar\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.1) # 底部留白\n",
    "    \n",
    "    cbar_ax = fig.add_axes([0.15, 0.05, 0.7, 0.02])\n",
    "    sm = plt.cm.ScalarMappable(cmap=new_cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, cax=cbar_ax, orientation='horizontal')\n",
    "    cbar.set_label('Coefficient of Variation (CV %)', fontsize=120, weight='bold') # 标签也加大\n",
    "    cbar.ax.tick_params(labelsize=120)\n",
    "    \n",
    "    save_path = os.path.join(Config.SAVE_DIR, \"All_Topologies_Row30.png\")\n",
    "    plt.savefig(save_path, dpi=600, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"  --> 保存成功: {save_path}\")\n",
    "\n",
    "# =========================================\n",
    "# 6. 主程序\n",
    "# =========================================\n",
    "if __name__ == \"__main__\":\n",
    "    model, cache_data, df, t_scaler, p_scaler = load_resources()\n",
    "    plot_all_topologies_in_one(df, model, cache_data, t_scaler, p_scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (zeolite_3d)",
   "language": "python",
   "name": "zeolite_3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
