{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de467bec-fb30-49d6-9c87-5aa3f1066221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 1. 正在加载数据集与缓存...\n",
      "    缓存加载成功。包含分子: 496, 沸石: 184\n",
      ">>> 2. 正在重建数据划分 (Random State = 42)...\n",
      ">>> 3. 拟合 Scaler 并准备测试集...\n",
      ">>> 4. 加载模型权重: zeolite_3d_gnn_enriched_cleaned.pth\n",
      "    模型权重加载成功！\n",
      ">>> 5. 开始测试集推理...\n",
      ">>> 6. 生成高标准分析图表...\n",
      "\n",
      "============================================================\n",
      "Target Variable                     | R²       | MAE      | MSE     \n",
      "-----------------------------------------------------------------\n",
      "    图表已保存: C:\\Users\\admin\\Energymodel\\2-9\\Analysis_Target_0_Binding_Energy.png\n",
      "Binding Energy (kJ/mol Si)          | 0.8361   | 1.0663   | 2.2569\n",
      "    图表已保存: C:\\Users\\admin\\Energymodel\\2-9\\Analysis_Target_1_Directivity_Energy.png\n",
      "Directivity Energy (kJ/mol Si)      | 0.8527   | 1.0781   | 2.3182\n",
      "    图表已保存: C:\\Users\\admin\\Energymodel\\2-9\\Analysis_Target_2_Competition_Energy.png\n",
      "Competition Energy (kJ/mol Si)      | 0.8459   | 1.1122   | 2.3770\n",
      "    图表已保存: C:\\Users\\admin\\Energymodel\\2-9\\Analysis_Target_3_Binding_Energy.png\n",
      "Binding Energy (kJ/mol OSDA)        | 0.8632   | 13.0874   | 396.3253\n",
      "    图表已保存: C:\\Users\\admin\\Energymodel\\2-9\\Analysis_Target_4_Competition_Energy.png\n",
      "Competition Energy (kJ/mol OSDA)    | 0.8002   | 13.1938   | 401.2538\n",
      "============================================================\n",
      "\n",
      "详细指标数据已保存至: C:\\Users\\admin\\Energymodel\\2-9\\metrics_summary.csv\n",
      "分析完成！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Batch, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "import warnings\n",
    "\n",
    "# 忽略不必要的警告\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==========================================\n",
    "# 1. 全局配置\n",
    "# ==========================================\n",
    "class Config:\n",
    "    # 基础路径\n",
    "    BASE_PATH = r\"C:\\机器学习材料\\季鏻\"\n",
    "    DATASET_PATH = os.path.join(BASE_PATH, \"MEL数据集.xlsx\")\n",
    "    \n",
    "    # 缓存与模型路径\n",
    "    PROCESSED_CACHE_PATH = os.path.join(BASE_PATH, \"cached_graphs_box64_cleaned.pt\")\n",
    "    MODEL_PATH = \"zeolite_3d_gnn_enriched_cleaned.pth\" \n",
    "    \n",
    "    # 输出图片路径\n",
    "    SAVE_DIR = r\"C:\\Users\\admin\\Energymodel\\2-9\"\n",
    "\n",
    "    TARGET_COLS = [\n",
    "        'Binding Energy (kJ/mol Si)',\n",
    "        'Directivity Energy (kJ/mol Si)',\n",
    "        'Competition Energy (kJ/mol Si)',\n",
    "        'Binding Energy (kJ/mol OSDA)',\n",
    "        'Competition Energy (kJ/mol OSDA)'\n",
    "    ]\n",
    "\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_WORKERS = 0 \n",
    "    \n",
    "    # 维度配置\n",
    "    ATOM_EMBEDDING_DIM = 64\n",
    "    HIDDEN_DIM = 128\n",
    "    EMB_DIM_DEGREE = 8\n",
    "    EMB_DIM_CHARGE = 8\n",
    "    EMB_DIM_HYB = 8\n",
    "    EMB_DIM_AROMATIC = 4\n",
    "    EMB_DIM_CHIRAL = 4\n",
    "\n",
    "    VOXEL_SIZE = 64\n",
    "    VOXEL_RES = 0.5\n",
    "    SIGMA = 0.5\n",
    "    MIN_SAMPLES_PER_TOPO = 0\n",
    "\n",
    "# 创建保存目录\n",
    "if not os.path.exists(Config.SAVE_DIR):\n",
    "    os.makedirs(Config.SAVE_DIR)\n",
    "    print(f\"创建输出目录: {Config.SAVE_DIR}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. 辅助函数\n",
    "# ==========================================\n",
    "def coords_to_voxel(coords, grid_size=32, res=0.5, sigma=0.5):\n",
    "    grid = np.zeros((grid_size, grid_size, grid_size), dtype=np.float32)\n",
    "    limit = (grid_size * res) / 2.0\n",
    "    mask = (coords[:, 0] > -limit) & (coords[:, 0] < limit) & \\\n",
    "           (coords[:, 1] > -limit) & (coords[:, 1] < limit) & \\\n",
    "           (coords[:, 2] > -limit) & (coords[:, 2] < limit)\n",
    "    valid_coords = coords[mask]\n",
    "    if len(valid_coords) == 0: return grid\n",
    "    indices = ((valid_coords + limit) / res).astype(int)\n",
    "    indices = np.clip(indices, 0, grid_size - 1)\n",
    "    for idx in indices:\n",
    "        x, y, z = idx\n",
    "        x_min, x_max = max(0, x-1), min(grid_size, x+2)\n",
    "        y_min, y_max = max(0, y-1), min(grid_size, y+2)\n",
    "        z_min, z_max = max(0, z-1), min(grid_size, z+2)\n",
    "        grid[x_min:x_max, y_min:y_max, z_min:z_max] += 1.0\n",
    "    return np.clip(grid, 0, 1.0)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 数据集定义\n",
    "# ==========================================\n",
    "class ZeoliteDataset(Dataset):\n",
    "    def __init__(self, df, cache_data, target_scaler=None, props_scaler=None, is_train=False):\n",
    "        super().__init__()\n",
    "        self.target_scaler = target_scaler if target_scaler else StandardScaler()\n",
    "        self.props_scaler = props_scaler if props_scaler else StandardScaler()\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        mol_cache = cache_data['mol_cache']\n",
    "        zeo_cache = cache_data['zeo_cache']\n",
    "        \n",
    "        self.mol_list = []\n",
    "        self.zeo_list = []\n",
    "        raw_y_list = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            cid = row['CID']\n",
    "            topo = row['Topology Code']\n",
    "            \n",
    "            if cid in mol_cache and topo in zeo_cache:\n",
    "                targets = row[Config.TARGET_COLS].values.astype(float)\n",
    "                if not np.isnan(targets).any():\n",
    "                    self.mol_list.append(mol_cache[cid])\n",
    "                    self.zeo_list.append(zeo_cache[topo])\n",
    "                    raw_y_list.append(targets)\n",
    "        \n",
    "        y_all = np.array(raw_y_list)\n",
    "        if is_train:\n",
    "            y_norm = self.target_scaler.fit_transform(y_all)\n",
    "        else:\n",
    "            y_norm = self.target_scaler.transform(y_all) if hasattr(self.target_scaler, 'mean_') else y_all\n",
    "            \n",
    "        self.y_list = [torch.tensor(y, dtype=torch.float) for y in y_norm]\n",
    "        \n",
    "        if len(self.mol_list) > 0:\n",
    "            all_props = torch.cat([m.global_attr for m in self.mol_list], dim=0).numpy()\n",
    "            if is_train:\n",
    "                self.props_scaler.fit(all_props)\n",
    "                \n",
    "        self.length = len(self.mol_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mol_data = self.mol_list[idx].clone()\n",
    "        zeo_data = self.zeo_list[idx].clone()\n",
    "        y = self.y_list[idx]\n",
    "\n",
    "        if hasattr(self.props_scaler, 'mean_'):\n",
    "            props_raw = mol_data.global_attr.numpy()\n",
    "            props_norm = self.props_scaler.transform(props_raw)\n",
    "            mol_data.global_attr = torch.tensor(props_norm, dtype=torch.float)\n",
    "\n",
    "        mol_coords = mol_data.pos.numpy()\n",
    "        if hasattr(mol_data, 'pos_variants'):\n",
    "            variants = mol_data.pos_variants\n",
    "            mol_coords = variants[0].numpy() \n",
    "            del mol_data.pos_variants\n",
    "\n",
    "        zeo_voxel_coords = zeo_data.pos_super.numpy() if hasattr(zeo_data, 'pos_super') else zeo_data.pos.numpy()\n",
    "        if hasattr(zeo_data, 'pos_super'): del zeo_data.pos_super \n",
    "\n",
    "        mol_data.pos = torch.tensor(mol_coords, dtype=torch.float)\n",
    "        \n",
    "        grid_mol = coords_to_voxel(mol_coords, Config.VOXEL_SIZE, Config.VOXEL_RES, Config.SIGMA)\n",
    "        grid_zeo = coords_to_voxel(zeo_voxel_coords, Config.VOXEL_SIZE, Config.VOXEL_RES, Config.SIGMA)\n",
    "        \n",
    "        voxel_tensor = torch.tensor(np.stack([grid_mol, grid_zeo], axis=0), dtype=torch.float)\n",
    "        \n",
    "        return mol_data, zeo_data, voxel_tensor, y\n",
    "\n",
    "    @staticmethod\n",
    "    def gpu_collate(batch):\n",
    "        mol_list = [item[0] for item in batch]\n",
    "        zeo_list = [item[1] for item in batch]\n",
    "        voxel_list = [item[2] for item in batch]\n",
    "        y_list = [item[3] for item in batch]\n",
    "        return (Batch.from_data_list(mol_list), Batch.from_data_list(zeo_list), torch.stack(voxel_list), torch.stack(y_list))\n",
    "\n",
    "# ==========================================\n",
    "# 4. 模型架构\n",
    "# ==========================================\n",
    "class Voxel3DCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(2, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(16)\n",
    "        self.pool1 = nn.MaxPool3d(2)\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(32)\n",
    "        self.pool2 = nn.MaxPool3d(2)\n",
    "        self.conv3 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm3d(64)\n",
    "        self.pool3 = nn.MaxPool3d(2)\n",
    "        self.fc = nn.Linear(64 * 8 * 8 * 8, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return x\n",
    "\n",
    "class DualBranchGNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb_atom = nn.Embedding(120, Config.ATOM_EMBEDDING_DIM)\n",
    "        self.emb_degree = nn.Embedding(12, Config.EMB_DIM_DEGREE)\n",
    "        self.emb_charge = nn.Embedding(15, Config.EMB_DIM_CHARGE)\n",
    "        self.emb_hyb = nn.Embedding(8, Config.EMB_DIM_HYB)\n",
    "        self.emb_aromatic = nn.Embedding(2, Config.EMB_DIM_AROMATIC)\n",
    "        self.emb_chiral = nn.Embedding(4, Config.EMB_DIM_CHIRAL)\n",
    "        \n",
    "        total_emb_dim = (Config.ATOM_EMBEDDING_DIM + Config.EMB_DIM_DEGREE + \n",
    "                         Config.EMB_DIM_CHARGE + Config.EMB_DIM_HYB + \n",
    "                         Config.EMB_DIM_AROMATIC + Config.EMB_DIM_CHIRAL)\n",
    "        \n",
    "        self.mol_conv1 = GCNConv(total_emb_dim + 1, Config.HIDDEN_DIM)\n",
    "        self.mol_conv2 = GCNConv(Config.HIDDEN_DIM, Config.HIDDEN_DIM)\n",
    "        self.zeo_conv1 = GCNConv(total_emb_dim, Config.HIDDEN_DIM)\n",
    "        self.zeo_conv2 = GCNConv(Config.HIDDEN_DIM, Config.HIDDEN_DIM)\n",
    "        self.voxel_cnn = Voxel3DCNN()\n",
    "        \n",
    "        self.global_feat_dim = 17\n",
    "        self.global_encoder = nn.Sequential(\n",
    "            nn.Linear(self.global_feat_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, Config.HIDDEN_DIM),\n",
    "            nn.BatchNorm1d(Config.HIDDEN_DIM),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        fusion_dim = Config.HIDDEN_DIM * 4\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, len(Config.TARGET_COLS))\n",
    "        )\n",
    "\n",
    "    def _embed_features(self, x_idx):\n",
    "        e1 = self.emb_atom(x_idx[:, 0])\n",
    "        e2 = self.emb_degree(x_idx[:, 1])\n",
    "        e3 = self.emb_charge(x_idx[:, 2])\n",
    "        e4 = self.emb_hyb(x_idx[:, 3])\n",
    "        e5 = self.emb_aromatic(x_idx[:, 4])\n",
    "        e6 = self.emb_chiral(x_idx[:, 5])\n",
    "        return torch.cat([e1, e2, e3, e4, e5, e6], dim=1)\n",
    "\n",
    "    def forward(self, mol_batch, zeo_batch, voxel_batch):\n",
    "        x_m, edge_index_m, batch_m = mol_batch.x, mol_batch.edge_index, mol_batch.batch\n",
    "        x_m_emb = self._embed_features(x_m)\n",
    "        x_m_in = torch.cat([x_m_emb, mol_batch.x_charge], dim=1)\n",
    "        x_m_out = F.relu(self.mol_conv1(x_m_in, edge_index_m, edge_weight=mol_batch.edge_weight))\n",
    "        x_m_out = F.relu(self.mol_conv2(x_m_out, edge_index_m, edge_weight=mol_batch.edge_weight))\n",
    "        feat_m = global_mean_pool(x_m_out, batch_m)\n",
    "        \n",
    "        x_z, edge_index_z, batch_z = zeo_batch.x, zeo_batch.edge_index, zeo_batch.batch\n",
    "        x_z_emb = self._embed_features(x_z)\n",
    "        x_z_out = F.relu(self.zeo_conv1(x_z_emb, edge_index_z))\n",
    "        x_z_out = F.relu(self.zeo_conv2(x_z_out, edge_index_z))\n",
    "        feat_z = global_mean_pool(x_z_out, batch_z)\n",
    "        \n",
    "        feat_v = self.voxel_cnn(voxel_batch)\n",
    "        \n",
    "        global_attr = mol_batch.global_attr\n",
    "        if global_attr.dim() == 3: global_attr = global_attr.squeeze(1)\n",
    "        feat_global = self.global_encoder(global_attr)\n",
    "        \n",
    "        combined = torch.cat([feat_m, feat_z, feat_global, feat_v], dim=1)\n",
    "        return self.head(combined)\n",
    "\n",
    "# ==========================================\n",
    "# 5. 加载数据与模型\n",
    "# ==========================================\n",
    "print(\">>> 1. 正在加载数据集与缓存...\")\n",
    "if not os.path.exists(Config.DATASET_PATH) or not os.path.exists(Config.PROCESSED_CACHE_PATH):\n",
    "    raise FileNotFoundError(\"数据文件或缓存文件缺失，请检查路径。\")\n",
    "\n",
    "df = pd.read_excel(Config.DATASET_PATH, engine='openpyxl')\n",
    "topo_counts = df['Topology Code'].value_counts()\n",
    "valid_topos = topo_counts[topo_counts >= Config.MIN_SAMPLES_PER_TOPO].index\n",
    "df_filtered = df[df['Topology Code'].isin(valid_topos)].reset_index(drop=True)\n",
    "\n",
    "try:\n",
    "    cache_data = torch.load(Config.PROCESSED_CACHE_PATH, weights_only=False)\n",
    "    print(f\"    缓存加载成功。包含分子: {len(cache_data['mol_cache'])}, 沸石: {len(cache_data['zeo_cache'])}\")\n",
    "except Exception as e:\n",
    "    print(f\"    缓存加载失败: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(\">>> 2. 正在重建数据划分 (Random State = 42)...\")\n",
    "indices = list(range(len(df_filtered)))\n",
    "train_idx, temp_idx = train_test_split(indices, train_size=0.8, random_state=42)\n",
    "val_idx, test_idx = train_test_split(temp_idx, train_size=0.5, random_state=42)\n",
    "\n",
    "print(\">>> 3. 拟合 Scaler 并准备测试集...\")\n",
    "train_dataset_dummy = ZeoliteDataset(df_filtered.iloc[train_idx].reset_index(drop=True), cache_data=cache_data, is_train=True)\n",
    "test_dataset = ZeoliteDataset(\n",
    "    df_filtered.iloc[test_idx].reset_index(drop=True), \n",
    "    cache_data=cache_data, \n",
    "    target_scaler=train_dataset_dummy.target_scaler, \n",
    "    props_scaler=train_dataset_dummy.props_scaler, \n",
    "    is_train=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=Config.BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=Config.NUM_WORKERS,\n",
    "    collate_fn=ZeoliteDataset.gpu_collate\n",
    ")\n",
    "\n",
    "print(f\">>> 4. 加载模型权重: {Config.MODEL_PATH}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DualBranchGNN().to(device)\n",
    "if os.path.exists(Config.MODEL_PATH):\n",
    "    state_dict = torch.load(Config.MODEL_PATH, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(\"    模型权重加载成功！\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"找不到模型文件: {Config.MODEL_PATH}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# ==========================================\n",
    "# 6. 推理与评估\n",
    "# ==========================================\n",
    "print(\">>> 5. 开始测试集推理...\")\n",
    "preds_list = []\n",
    "targets_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for mol, zeo, voxel, y in test_loader:\n",
    "        mol, zeo, voxel, y = mol.to(device), zeo.to(device), voxel.to(device), y.to(device)\n",
    "        output = model(mol, zeo, voxel)\n",
    "        preds_list.append(output.cpu().numpy())\n",
    "        targets_list.append(y.cpu().numpy())\n",
    "\n",
    "preds_norm = np.vstack(preds_list)\n",
    "targets_norm = np.vstack(targets_list)\n",
    "\n",
    "y_pred = train_dataset_dummy.target_scaler.inverse_transform(preds_norm)\n",
    "y_true = train_dataset_dummy.target_scaler.inverse_transform(targets_norm)\n",
    "\n",
    "# ==========================================\n",
    "# 7. 绘图与分析 (NCS 风格优化版)\n",
    "# ==========================================\n",
    "print(\">>> 6. 生成高标准分析图表...\")\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 18,\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Arial', 'Helvetica', 'DejaVu Sans'],\n",
    "    'axes.labelsize': 20,\n",
    "    'axes.titlesize': 22,\n",
    "    'xtick.labelsize': 16,\n",
    "    'ytick.labelsize': 16,\n",
    "    'legend.fontsize': 16,\n",
    "    'figure.dpi': 300,\n",
    "    'axes.linewidth': 1.5,\n",
    "    'grid.alpha': 0.4\n",
    "})\n",
    "\n",
    "# 1. 设置色谱\n",
    "magma = cm.get_cmap('magma')\n",
    "new_colors = magma(np.linspace(0.3, 1, 256)) # 从 30% 开始，避免黑色\n",
    "custom_magma = mcolors.LinearSegmentedColormap.from_list(\"trunc_magma\", new_colors)\n",
    "\n",
    "# 2. 提取用于边缘图的协调颜色 (选取 Magma 色谱中段的深紫色)\n",
    "marginal_color = magma(0.35) \n",
    "\n",
    "def plot_marginal_density(y_t, y_p, title, filename_suffix):\n",
    "    r2 = r2_score(y_t, y_p)\n",
    "    mae = mean_absolute_error(y_t, y_p)\n",
    "    mse = mean_squared_error(y_t, y_p)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    data = pd.DataFrame({'Experimental': y_t, 'Predicted': y_p})\n",
    "    \n",
    "    xy = np.vstack([y_t, y_p])\n",
    "    try:\n",
    "        z = gaussian_kde(xy)(xy)\n",
    "        idx = z.argsort()\n",
    "        x_sorted, y_sorted, z_sorted = y_t[idx], y_p[idx], z[idx]\n",
    "    except:\n",
    "        x_sorted, y_sorted, z_sorted = y_t, y_p, np.ones_like(y_t)\n",
    "\n",
    "    # 绘图\n",
    "    g = sns.JointGrid(x='Experimental', y='Predicted', data=data, height=8, ratio=5)\n",
    "    \n",
    "    # 中心图\n",
    "    g.ax_joint.scatter(x_sorted, y_sorted, c=z_sorted, cmap=custom_magma, s=40, edgecolor='none', alpha=0.9)\n",
    "    \n",
    "    # 辅助线\n",
    "    min_val = min(y_t.min(), y_p.min())\n",
    "    max_val = max(y_t.max(), y_p.max())\n",
    "    margin = (max_val - min_val) * 0.05\n",
    "    lims = [min_val - margin, max_val + margin]\n",
    "    \n",
    "    g.ax_joint.plot(lims, lims, '--', color='gray', alpha=0.7, linewidth=2, label='Ideal')\n",
    "    g.ax_joint.set_xlim(lims)\n",
    "    g.ax_joint.set_ylim(lims)\n",
    "    \n",
    "    # 边缘图 (使用从 magma 提取的统一颜色，实现视觉协调)\n",
    "    sns.histplot(data=data, x='Experimental', ax=g.ax_marg_x, fill=True, \n",
    "                 color=marginal_color, alpha=0.7, kde=True, line_kws={'linewidth': 2, 'color': 'k'})\n",
    "    sns.histplot(data=data, y='Predicted', ax=g.ax_marg_y, fill=True, \n",
    "                 color=marginal_color, alpha=0.7, kde=True, line_kws={'linewidth': 2, 'color': 'k'})\n",
    "    \n",
    "    # 文本标注 (已移除 MSE 和 N)\n",
    "    stats_text = (f'$R^2 = {r2:.4f}$\\n'\n",
    "                  f'$MAE = {mae:.4f}$\\n'\n",
    "                  f'$RMSE = {rmse:.4f}$')\n",
    "    \n",
    "    g.ax_joint.text(0.05, 0.95, stats_text, transform=g.ax_joint.transAxes,\n",
    "                    verticalalignment='top', fontsize=20, # 字大一点\n",
    "                    bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    \n",
    "    g.ax_joint.set_xlabel(f'Experimental {title}', fontweight='bold')\n",
    "    g.ax_joint.set_ylabel(f'Predicted {title}', fontweight='bold')\n",
    "    \n",
    "    save_path = os.path.join(Config.SAVE_DIR, f\"Analysis_{filename_suffix}.png\")\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"    图表已保存: {save_path}\")\n",
    "    \n",
    "    return r2, mae, mse, rmse\n",
    "\n",
    "metrics_summary = []\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"{'Target Variable':<35} | {'R²':<8} | {'MAE':<8} | {'MSE':<8}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for i, col_name in enumerate(Config.TARGET_COLS):\n",
    "    clean_name = col_name.split(' (')[0].replace(' ', '_').replace('/', '_')\n",
    "    unit_label = col_name \n",
    "    \n",
    "    r2, mae, mse, rmse = plot_marginal_density(y_true[:, i], y_pred[:, i], unit_label, f\"Target_{i}_{clean_name}\")\n",
    "    \n",
    "    print(f\"{col_name[:35]:<35} | {r2:.4f}   | {mae:.4f}   | {mse:.4f}\")\n",
    "    metrics_summary.append([col_name, r2, mae, mse, rmse])\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "csv_path = os.path.join(Config.SAVE_DIR, \"metrics_summary.csv\")\n",
    "df_metrics = pd.DataFrame(metrics_summary, columns=['Target', 'R2', 'MAE', 'MSE', 'RMSE'])\n",
    "df_metrics.to_csv(csv_path, index=False)\n",
    "print(f\"\\n详细指标数据已保存至: {csv_path}\")\n",
    "print(\"分析完成！\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (zeolite_3d)",
   "language": "python",
   "name": "zeolite_3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
